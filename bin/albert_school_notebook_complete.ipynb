{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ab24b4f",
   "metadata": {},
   "source": [
    "## Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c69c804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Optional, Tuple\n",
    "from collections import Counter\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import calendar\n",
    "import configparser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dcdafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seting up the configuration file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('../cfg/config.ini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9169cafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set pandas display options\n",
    "# Adjust number of decimal displayed\n",
    "pd.options.display.float_format = '{:.1f}'.format\n",
    "# Adjust pandas settings to display all rows\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4266119",
   "metadata": {
    "tags": []
   },
   "source": [
    "## First step: Load datasets as Pandas *Dataframes*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bf8b89",
   "metadata": {},
   "source": [
    "Set your working directory to the one containing the datasets to make it easier to load them in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04648c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the current working directory\n",
    "print('Current working directory: ' + os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaa1969-2850-4463-b8b0-186b313c45b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the current working directory if needed\n",
    "#os.chdir(\"C:/path/to/new/directory\")\n",
    "os.chdir(\"/media/data/lvmh\")\n",
    "# Print the new current working directory\n",
    "print('Current working directory: ' + os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362be1da-edc6-4699-b647-d95eb64ea8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the files/datasets list in the working directory\n",
    "print(os.listdir(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dff97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets using the read_csv() method. You can specify the separator used in the csv file. By default, the separator is \",\"\n",
    "products_df = pd.read_csv('product_inf_2000.csv')\n",
    "client_df = pd.read_csv('client_inf_2000.csv',sep=';')\n",
    "transactions_df = pd.read_csv('transac_inf_2000.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8043cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "products = pd.read_csv('product.csv')\n",
    "client = pd.read_csv('client.csv', sep=';')\n",
    "transactions = pd.read_csv('transac.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca676d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concaténation des DataFrames\n",
    "combined_products = pd.concat([products, products_df], ignore_index=True)\n",
    "\n",
    "# Harmonisation des types de colonnes selon le plus grand DataFrame\n",
    "for col in products_df.columns:\n",
    "    combined_products[col] = combined_products[col].astype(products_df[col].dtype)\n",
    "\n",
    "# Vérification des informations du DataFrame combiné\n",
    "print(combined_products.info())\n",
    "\n",
    "# Optionnel : sauvegarde en CSV\n",
    "combined_products.to_csv('combined_products.csv', index=False, sep=',', na_rep='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f3249c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concaténation des DataFrames\n",
    "combined_client = pd.concat([client, client_df], ignore_index=True)\n",
    "\n",
    "# Harmonisation des types de colonnes selon client_df (le plus grand DataFrame)\n",
    "for col in client_df.columns:\n",
    "    combined_client[col] = combined_client[col].astype(client_df[col].dtype)\n",
    "\n",
    "# Vérification des informations du DataFrame combiné\n",
    "print(combined_client.info())\n",
    "\n",
    "# Optionnel : sauvegarde en CSV\n",
    "combined_client.to_csv('combined_client.csv', index=False, sep=',', na_rep='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ee93d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions.info()\n",
    "transactions_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96faa46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Renommer la colonne 'website_version' en 'country' pour uniformiser\n",
    "transactions_df = transactions_df.rename(columns={'website_version': 'country'})\n",
    "\n",
    "# Concaténation\n",
    "combined_transactions = pd.concat([transactions, transactions_df], ignore_index=True)\n",
    "\n",
    "# Harmonisation des types selon transactions_df\n",
    "for col in transactions_df.columns:\n",
    "    combined_transactions[col] = combined_transactions[col].astype(transactions_df[col].dtype)\n",
    "\n",
    "# Vérification\n",
    "print(combined_transactions.info())\n",
    "\n",
    "# Optionnel : sauvegarde en CSV\n",
    "combined_transactions.to_csv('combined_transactions.csv', index=False, sep=',', na_rep='')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d1d28d",
   "metadata": {},
   "source": [
    "The head() method on Dataframes displays the top 5 rows. The tail() method displays the last 5 rows. You can tune the number of rows to diplay in parameters, for example try head(10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57229a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a sample of data with the head() method\n",
    "combined_products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db5a705-40b8-4d82-a9ef-14a66e4375bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a sample of data with the tail() method\n",
    "combined_transactions.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81901c7-aa94-4fde-954f-da2e74ebdb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a sample of data with the tail() method\n",
    "combined_client.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3135b08-1862-4468-ac8c-4158120575f3",
   "metadata": {},
   "source": [
    "The info() method is also useful to have a short report of the dataframe and its data quality:\n",
    "* number of rows\n",
    "* column name\n",
    "* column type\n",
    "* Number of missing cells of a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d85128-89dc-4cb8-8385-dac75a39e990",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_products.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a12fda-cf5c-4483-9594-44e9fc439d20",
   "metadata": {},
   "source": [
    "While the `products_df` dataframe describe products (each product_id is called a \"SKU\" for *Stock Keeping Unit*) and their attributes, `transactions_df` will give very useful details about sales: which product is sold? Which quantity? Which store? When?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e788ee12-98ef-44b4-a1bb-d8095f857e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_client.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a622cc51-d776-4daa-b677-4ea1dc5a14e9",
   "metadata": {},
   "source": [
    "The client_df dataframe will give you information on the clients' profiles and purchasing habits. Which kind of clients purchased which products? In what quantity? By which channel? In which country ?..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe3f670-856c-473f-94f9-0e7664681cd7",
   "metadata": {},
   "source": [
    "The Clients Table is particular: each line doesn't correspond to a client, but is at the granularity group of clients x week x product macro family x age x nationality x reachability x is_big_client x channel of purchase x zone of purchase.\n",
    "\n",
    "For reasons of privacy, we had to regroup the clients in terms of age, etc. The column 'clients' represents the group size. The \"items_bought\" columns indicate the quantity purchased.\n",
    "\n",
    "Yet that is not a very convenient table to handle as such. We would prefer that each line corresponds to a client. Therefore, we are going to make an approximation by stating that each line corresponds to a client, whose number of items bought is the one indicated in the table, divided by the cluster size.\n",
    "\n",
    "That will be an opportunity for us to learn how to build new columns based on other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce4a271-872b-4f9c-9566-1f374d87261a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the average number of products purchased per client in each group:\n",
    "combined_client['items_bought_norm'] = combined_client['items_bought'] / combined_client['clients']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f012d8-305b-46f6-bf31-7e9e4c7f6cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_client['items_bought_norm'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cbae9e-f7c2-46ff-9ff1-bde9d22614ad",
   "metadata": {},
   "source": [
    "On average, a client has purchased 1,17 products."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38200acc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Exploration: Compute basic statistics on data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574bb9f6",
   "metadata": {},
   "source": [
    "The describe() method computes basic statistics on numerical columns. On the example below the only numerical column is the price, hence the method computes count, mean, standard deviation, minimum and maximum value and quantiles for the price column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed21df93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The describe() method computes basic statistics on numerical columns\n",
    "combined_products.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ecf339",
   "metadata": {},
   "source": [
    "You can use the nunique() method to get the number of distinct values for all columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958f9c35-47d5-4bb8-ab33-10dabe61ee8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_transactions.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4e0b5d-e940-4275-b97a-f1348b3ebfb8",
   "metadata": {},
   "source": [
    "You can also apply the same method to a specific column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d6e7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of distinct SKUs sold\n",
    "combined_transactions['product_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9815b75-7261-4e85-929b-41f2561627f1",
   "metadata": {},
   "source": [
    "If you're interested in a specific column, you can apply the unique() method at column-level to obtain an array of all the distinct values in this column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc15d2c-0f81-4cda-928f-9c947df4ad88",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_transactions['product_id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60e4a6a-f097-4920-a323-ef18537aa6ac",
   "metadata": {},
   "source": [
    "## Basic Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bdcc4f",
   "metadata": {},
   "source": [
    "Use the mean() method to quickly compute the average over a dataframe's column. You can check the result is the same as the one given by the describe() method above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4417fb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the average price of products\n",
    "combined_products['price_fr_eur'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ab9412-64ab-47c8-bc23-de61fb95936d",
   "metadata": {},
   "source": [
    "mean() is part of a list of computing methods you can use for any numerical column: mean, sum, max, min..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a612f3-c06f-49bd-a7ad-1feb21807a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the min and max price of products\n",
    "print(\n",
    "    'Minimum price of the products dataframe: {}'.format(combined_products['price_fr_eur'].min()),\n",
    "    'Maximum price of the products dataframe: {}'.format(combined_products['price_fr_eur'].max()),\n",
    "    sep='\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dd5f89-01a0-4e14-a1e5-2f943de38153",
   "metadata": {},
   "source": [
    "Computing statistics is part of data exploration, essential in all data analysis and data science projets. Product, store and transaction data are mandatory for analyzing how products/collections are successful through time and space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345ff185-b4cc-498a-b881-7a46ba3b6bf5",
   "metadata": {},
   "source": [
    "Using value_counts() method, you can have a quick overview of products popularity on the website in a selected country for example. Actually, value_counts() method computes the number of occurrences for each value of a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f156ef2-595e-4aa8-8f76-9a9058a77632",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_transactions.product_id.nunique(), combined_transactions.product_id.unique(), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8dcf0f-94cc-47d4-8719-3260acdfb336",
   "metadata": {},
   "source": [
    "Below, the number of occurrences correspond to the number of rows in the dataframe for each country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3aa29a2-8ac4-46e6-b9cb-86aa0df58786",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Top countries in website data\n",
    "combined_transactions.country.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a024aac-3bc8-4d45-a3ff-0ce07dab859c",
   "metadata": {},
   "source": [
    "You can use the to_frame() method to get a more readable version of the result displayed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288e53a5-c621-42de-b916-bac08a2521ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the value counts and directly convert to a DataFrame\n",
    "version_counts_df = combined_transactions['country'].value_counts().to_frame().reset_index()\n",
    "# Rename columns for clarity\n",
    "version_counts_df.columns = ['Country', 'Count']\n",
    "# Display the DataFrame\n",
    "version_counts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219ca95b-6813-4eb9-baf1-e73f7e37fbe6",
   "metadata": {},
   "source": [
    "How to compute the most represented SKU in transaction data? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bca6642-be15-418b-a9df-f1cee0e89c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_transactions.product_id.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6c63bd-bc38-434c-bf01-b5a68614a719",
   "metadata": {},
   "source": [
    "As you can see above, you can chain multiple methods: here head() follows value_counts()."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebd689a-e31f-4367-a948-df49b1cc1064",
   "metadata": {},
   "source": [
    "If you want to look at the data for a specific value of a specific column, below a simple way to do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15e4a87-495c-4416-ba15-86db7d2d9c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the shape of web_df dataframe, i.e. show the tuple (number of rows, number of columns)\n",
    "print(combined_transactions.shape)\n",
    "\n",
    "# Now show the shape of France rows\n",
    "print(combined_transactions[combined_transactions.country == 'FRANCE'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fb7205-0f8f-4d6b-b35a-15a998417a7b",
   "metadata": {},
   "source": [
    "Now let's have a look to the most represented country: China. Are these top products the same as for a specific country?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53275de1-101c-408b-82d4-bacc5bba207d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 SKU with the greatest number of rows in China\n",
    "combined_transactions[combined_transactions.country == 'CHINA'].product_id.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2912ca37-5623-4797-9cd5-13c1cd1c9e62",
   "metadata": {},
   "source": [
    "Is the number of rows the right indicator for defining product populariy? Insights will depend on your ability to identify the right indicators to consider. Rather than using the number of rows, transaction data may have more interesting column like sales, number of clients or number of transactions...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920fb373",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Join Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c043e9dc",
   "metadata": {},
   "source": [
    "You'll have noticed that some datasets have supplementary information from one another. For example, we would like to add the product's information in the transactions dataset.\n",
    "To do this, use the merge() method. If you are familiar with SQL the merge() method works similarly as as JOIN between tables. You will need to specify the type of join you want. We typically use left join, meaning we keep all data from the left dataset and will add matching rows from the right dataset. And specify the key for joining, which is the column that is present in both datasets.\n",
    "\n",
    "For more information about dataframe merging in pandas, this page https://pandas.pydata.org/docs/user_guide/merging.html is a nice reading!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a65631f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge transactions and products datasets\n",
    "transactions_with_product = combined_transactions.merge(combined_products, how='left', left_on='product_id', right_on='product_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1614b9",
   "metadata": {},
   "source": [
    "In the new dataframe transactions_with_product, we will have all the transactions lines with the corresponding products data added in each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330320f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a sample of the new merged dataframe\n",
    "transactions_with_product.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298485cf-d188-450c-9c1a-c989ae5d93be",
   "metadata": {},
   "source": [
    "As precised above, a left join will keep all the data from the left dataframe (here `transactions_df`) while adding the information from the right dataframe. This addition is based on the keys given by `left_on` and `right_on` args. Actually, if the keys have the same value, you can just consider `on` arg:\n",
    "```python\n",
    "transactions_with_product = transactions_df.merge(products_df, how='left', on='product_id')\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bae1430-fbcc-4dfe-a87c-aba5bdaf0264",
   "metadata": {},
   "source": [
    "It is always a good idea to check that you have not lost or gained any data after a merge! To this end, you can compare the number of rows in your dataframes before and after the merge. They need to be the same.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc68651-5bb5-40d9-aa56-469487ea0354",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_transactions.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c3ee7f-bec0-49e4-a31d-835d24f319f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_with_product.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637646e8-7308-4072-86a2-93df36b14bb6",
   "metadata": {},
   "source": [
    "You could do the same thing with the client_df and product_df dataframe!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79761af",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Compute columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0233426c",
   "metadata": {},
   "source": [
    "You might want to compute columns. For example, in our new dataset we have for each transaction the number of SKUs sold. And we have added the price of each SKU from the products dataframe. We would like to compute the total corresponding amount for each line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a648f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the total sale amount as a new column of the dataframe\n",
    "transactions_with_product['sale_amount'] = transactions_with_product['product_quantity'] * transactions_with_product['price_fr_eur']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a849cf16",
   "metadata": {},
   "source": [
    "Now our dataframe contains an additional column named \"sale_amount\" that contains the total sales amount. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e144ba0e-b46e-41de-bd3d-590f39bea8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_with_product['sale_amount'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b93fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample data from our dataframe\n",
    "transactions_with_product.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a06ea7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Aggregate Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878d8929",
   "metadata": {},
   "source": [
    "Now, let's say we would like to compute the weekly turnover by year on those products.\n",
    "We would need to aggregate our total sales by week. The first step is to extract the year and week from our dates. Now, look at the week format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c45e17-bd17-4f6a-9754-a0abe65c4b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_with_product['week'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159d47fe-467d-411b-af35-1d39b3a391bf",
   "metadata": {},
   "source": [
    "It's a string! We can isolate the year and the week in two separate columns, then convert them to integers with the .astype() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3084f457-21b2-40ca-98e2-7c667cf0cb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the 'week_column' into 'year' and 'week_number'\n",
    "transactions_with_product['year'] = transactions_with_product['week'].str[1:5].astype(int)  # Extract the year part\n",
    "transactions_with_product['week_number'] = transactions_with_product['week'].str[5:].astype(int)  # Extract the week number part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2914a495-96fe-4373-a4a0-12090c66b003",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check that both columns are integer with the dtypes method:\n",
    "transactions_with_product.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46883dd7-9d2f-4f1f-a65d-cf156061a435",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_with_product.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88b54ec",
   "metadata": {},
   "source": [
    "Now we want to sum all the sales amounts for each year and week.\n",
    "If you are familiar with SQL, it is similar to the GROUP BY function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f8fce1-c9c3-4e64-9234-8297e5b52174",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Obtain total sales amount by year and week:\n",
    "transactions_agg = transactions_with_product[['year','week_number', 'sale_amount']].groupby(by=['year','week_number']).sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b1f8d2",
   "metadata": {},
   "source": [
    "The sum method added in the end will compute the sum over all numerical columns not used in the \"group by\". Hence the resulting dataframe will have summed the number of sales amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1096ccd7-f10b-4a09-a657-e3f8220fd57b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "transactions_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1298bc-1d3b-4d0e-ba0d-6263eff073f6",
   "metadata": {},
   "source": [
    "You can also directly specify the columns on which performing aggregations, then reset the index of the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8b6d87-d9f0-404f-bd04-6bd454cb3f0d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "minimal_transactions_agg = transactions_with_product[\n",
    "    ['year','week_number', 'sale_amount']\n",
    "].groupby(\n",
    "    by=['year','week_number']\n",
    ").sum().reset_index(drop=False)\n",
    "\n",
    "minimal_transactions_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f458ade0-97ab-4600-9baa-239a61b41964",
   "metadata": {},
   "source": [
    "Now, you can compare `sale_amount` values for the same week in different years:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d07598-eecf-4df2-9c5d-44d19fe6908d",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimal_transactions_agg[minimal_transactions_agg.week_number == 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c5456a-e6d2-45bc-aa97-f293829128d8",
   "metadata": {},
   "source": [
    "You can sort your aggregated dataframe on `sale_amount`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd99473-0884-48d4-a721-6cc10725f999",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimal_transactions_agg[minimal_transactions_agg.week_number == 6].sort_values('sale_amount', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7859cae4-894c-404e-893e-37808bac3865",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimal_transactions_agg[minimal_transactions_agg.week_number == 6].sale_amount.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1202ec30-86cb-488f-88e7-c4e53f989a1c",
   "metadata": {},
   "source": [
    "We can thus observe an sales amount increase for week number 6 through the last 2 years."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c73b9b-2081-4653-a1c8-e9017d21d47b",
   "metadata": {},
   "source": [
    "Previously, we saw that value_counts() method allows to compute number of occurrences for column values. Actually, you also do it in a different way with groupby-like aggregations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51e1fe9-660c-4728-8318-9ec96d844cac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Top countries in number of products with value_counts\n",
    "combined_transactions.country.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54397a7-ec9b-48bf-a94a-072d4cbb93a5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Top countries in number of products with groupby and count agg\n",
    "combined_transactions.groupby('country')[['product_id']].count().sort_values('product_id', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbd00d8-f392-44bf-9608-8573ee1226b3",
   "metadata": {},
   "source": [
    "Since value_counts() gives you the number of rows, count() agg gives you the number of cells per column. In this case, it just appears as a more complicated way to do the same thing.\n",
    "\n",
    "Now, remember when we wanted to compute top SKU for China with a filter? Now with groupby aggregation we can do it for all countries!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a61ee2-8ac4-4b98-9759-108ad6e648c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "country_sku_occurrences = combined_transactions.groupby(\n",
    "    ['country', 'product_id']\n",
    ").count().reset_index(drop=False).rename(\n",
    "    columns={'week': 'COUNT'}\n",
    ")[\n",
    "    ['country', 'product_id', 'COUNT']\n",
    "]\n",
    "\n",
    "country_sku_occurrences.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90877541-4a7d-4e95-beca-07c2b1093e8c",
   "metadata": {},
   "source": [
    "Do we have the same results as previously?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a806c3-369c-44e1-9bfe-be2625c1b94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_transactions[combined_transactions.country == 'CHINA'].product_id.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29af8d22-7ffd-449b-a910-60372d74c338",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_sku_occurrences[\n",
    "   country_sku_occurrences.country == 'CHINA'\n",
    "].sort_values(\n",
    "    'COUNT', ascending=False\n",
    ").head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae5fb0f-7dfc-4a9f-b82c-22ad6f7c1001",
   "metadata": {},
   "source": [
    "The only (and major) difference is that now, with the groupby method, these occurrences are computed and stored for all countries. With value_counts() method, each call to this method will involve a new compute. If you deal with big data, it may be more comfortable to get already computed and stored results instead of re-compute them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5dbcae-e394-4d09-b047-cdc73a85ae3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_sku_occurrences[\n",
    "    country_sku_occurrences.country == 'FRANCE'\n",
    "].sort_values(\n",
    "    'COUNT', ascending=False\n",
    ").head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a035a7e-822a-4c02-811b-29ade5d05644",
   "metadata": {},
   "source": [
    "Let's explore time of execution for both methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352e8c96-aad0-4b9b-863c-2c3172942c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "combined_transactions[combined_transactions.country == 'CHINA'].product_id.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978d3cf3-ea60-4745-8e0d-0aedb19f22ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "country_sku_occurrences[\n",
    "   country_sku_occurrences.country == 'CHINA'\n",
    "].sort_values(\n",
    "    'COUNT', ascending=False\n",
    ").head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca475a6-8521-4c0e-9d69-a915ff2d09bf",
   "metadata": {},
   "source": [
    "Our new method with groupby-aggregation is far faster than the previous one with value_count()."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9182c94e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Plot Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f12836",
   "metadata": {},
   "source": [
    "It would be nicer to plot these data on a graph to see the evolution of the weekly turnover.\n",
    "To analyse a weekly turnover, it might be more relevant to narrow it down to a product or a product category.\n",
    "Let's compute a new aggregation level for a given category (here, we will use the field: macro_family which works like a \"category\" field)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffb860f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are all the product macro_family models\n",
    "transactions_with_product['macro_family'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d799fbca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This line gives the overall descending ranking of best-selling macro families in sales\n",
    "transactions_with_product[\n",
    "    ['macro_family','sale_amount']\n",
    "].groupby(\n",
    "    by=['macro_family']\n",
    ").sum().sort_values(\n",
    "    by='sale_amount', ascending=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddd98da",
   "metadata": {},
   "source": [
    "You can also use .loc[] to filter your dataframe. The resulting dataframe will contain only the lines corresponding to your filters. In the example below, the only remaining rows are going to be the ones related to the \"CITY BAGS\" product family."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102e72a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's select the overall best selling macro family = CITY BAGS\n",
    "transactions_citybags = transactions_with_product.loc[transactions_with_product['macro_family'] == 'CITY BAGS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91550678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's aggregate this dataframe. You can specify which column you want to sum on:\n",
    "transactions_citybags_agg = transactions_citybags.groupby(by=['year','week_number'])['sale_amount'].sum()\n",
    "transactions_citybags_agg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbdd547",
   "metadata": {},
   "source": [
    "Now, we have in our transactions_citybags_agg dataframe the aggregated sales amounts for the \"City Bags\" products only.\n",
    "We can display this data on a chart.  \n",
    "There are several ways to plot data in Python, we are going to use the pandas native one using the plot() method.  \n",
    "\n",
    "*Note that here, our dataframe is already indexed by year and week, so you can use it as your X axis with the parameter \"use_index=True\". If you want to plot againt another variable, you can specify it in the \"x=\" parameter and get rid of the \"use_index=True\".*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e28045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the total sale amount with respect to year-week\n",
    "transactions_citybags_agg.plot(kind='line', figsize=(15, 6), y='sale_amount', use_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41172f03-469f-4317-9fae-42640d71b8c3",
   "metadata": {},
   "source": [
    "If we want to make the x axis more clear, we can format the week indicator to display the corresponding month and year. Note how we manage the weeks 53 and 0 which are invalid week numbers for this specific function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae645c75-4803-4f8b-b2bb-6b967cacfad0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_month_and_year(week_string):\n",
    "    # Extract the year and week number from the input string\n",
    "    year_str = week_string[1:5]\n",
    "    week_num_str = week_string[5:]\n",
    "\n",
    "    # Convert the year and week number to integers\n",
    "    year = int(year_str)\n",
    "    week_num = int(week_num_str)\n",
    "\n",
    "    # Extract the month and year of every day of the week and chose the average month and year\n",
    "    months, years = [], []\n",
    "    try:\n",
    "            # Handle week 0 (January of the given year)\n",
    "            if week_num == 0:\n",
    "                day = datetime.date.fromisocalendar(year, 1, 1)  # First day of the year\n",
    "                months.append(day.month)\n",
    "                years.append(day.year)\n",
    "    \n",
    "            # Handle valid week numbers (1 to 52, or 53 if valid)\n",
    "            else:\n",
    "                for i in range(1, 8):  # Iterate over the days of the week\n",
    "                    day = datetime.date.fromisocalendar(year, week_num, i)\n",
    "                    months.append(day.month)\n",
    "                    years.append(day.year)\n",
    "    \n",
    "    except ValueError:\n",
    "            # Handle invalid week numbers (like non-existent week 53)\n",
    "            last_day_of_year = datetime.date(year, 12, 31)\n",
    "            months.append(last_day_of_year.month)\n",
    "            years.append(last_day_of_year.year)\n",
    "        \n",
    "    average_month = Counter(months).most_common(1)[0][0]\n",
    "    average_year = Counter(years).most_common(1)[0][0]\n",
    "\n",
    "    # Convert the month to the corresponding label\n",
    "    month = calendar.month_name[average_month]\n",
    "\n",
    "    return month[:3] + '-' + str(average_year)\n",
    "\n",
    "#Example\n",
    "week_string = \"W202148\"\n",
    "print(get_month_and_year(week_string))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23687317-246d-4bab-afd3-2d144758b714",
   "metadata": {},
   "source": [
    "Now we can remap the x axys to display the corresponding month and year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00eca358-51fd-40f2-ab3a-b35d058bb2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "week_sales = transactions_citybags.groupby(by=['week'])['sale_amount'].sum()\n",
    "week_sales = week_sales.reset_index(drop=False)\n",
    "week_sales['month_year'] = week_sales['week'].apply(get_month_and_year)\n",
    "\n",
    "# Convert 'month_year' to date (using the datetime method) for sorting in order to keep a chronological order in your plot\n",
    "week_sales['month_year_datetime'] = pd.to_datetime(week_sales['month_year'], format='%b-%Y')\n",
    "\n",
    "## Aggregate to monthly sales:\n",
    "month_sales = week_sales.groupby(by=['month_year_datetime'])['sale_amount'].sum().reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb49afdb-bd01-4899-9932-46c55740d512",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot monthly sales\n",
    "month_sales.plot(kind='line', figsize=(15,6), y='sale_amount', x='month_year_datetime', rot=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2abba2-6522-44da-b592-45eed3afa040",
   "metadata": {},
   "source": [
    "To understand the sales part of each universe, store_type, gender, it's prefered to use an histogram plot rather than a classic graph, as it greatly improves both explainability and readability.\n",
    "\n",
    "Besides, we can use the method plt.subplots() in order to show several plots on a unique figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f239d898-06ea-4510-88d1-529c8f95d0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_with_product.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f188203-8594-4e23-bbc1-6f04f01b5c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "universe_sales = transactions_with_product.groupby(by='universe')['sale_amount'].sum()\n",
    "gender_sales = transactions_with_product.groupby(by='gender')['sale_amount'].sum()\n",
    "type_sales = transactions_with_product.groupby(by='store_type_label')['sale_amount'].sum()\n",
    "\n",
    "plots = [universe_sales, gender_sales, type_sales]\n",
    "fig, axs = plt.subplots(len(plots), 1, figsize=(7, 3*len(plots)))\n",
    "\n",
    "\n",
    "for i in range(len(plots)):\n",
    "    axs[i].hist(x=plots[i].index, weights=plots[i], label='Sales')\n",
    "    axs[i].legend()\n",
    "\n",
    "# Rotate x-axis labels by 45 degrees\n",
    "    axs[i].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()  # Adjust layout to prevent label overlap\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c16396e-bcc3-485f-aaa4-22aae257fa08",
   "metadata": {},
   "source": [
    "To view the same repartition but on a specified selection of data we can compute extracts of the main dataframe following the conditions wanted. Here let's compare the sales in a specific category in two different regions of the world."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e4aa77-483a-4f28-ba26-59b022ce1943",
   "metadata": {},
   "source": [
    "Wich category should we choose? Let's look at our best-selling macro_families:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa75230-1b3d-4f5a-9f55-cbf4418a92d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transactions_with_product[\n",
    "    ['macro_family','sale_amount']\n",
    "].groupby(\n",
    "    by=['macro_family']\n",
    ").sum().sort_values(\n",
    "    by='sale_amount', ascending=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42034bb-f78a-4f18-aa14-be07651310bf",
   "metadata": {},
   "source": [
    "As the very best-selling category, we will focus on City bags once again. Now, which countries should we compare? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3df4178-361b-4096-994b-36cfc04bc130",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transactions_with_product[\n",
    "    ['country','sale_amount']\n",
    "].groupby(\n",
    "    by=['country']\n",
    ").sum().sort_values(\n",
    "    by='sale_amount', ascending=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809c9fac-3482-428c-bdb0-e2861f19f6d9",
   "metadata": {},
   "source": [
    "Let's take the top 2: China and Japan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4da2d0e-5581-4d29-abba-50dd5b9524ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Isolate the CITY BAGS  transactions as we did earlier:\n",
    "transactions_citybags = transactions_with_product.loc[transactions_with_product['macro_family'] == 'CITY BAGS']\n",
    "\n",
    "# Let's aggregate this dataframe for each week in each region\n",
    "transactions_citybags_agg = transactions_citybags.groupby(by=['week','country'])['sale_amount'].sum()\n",
    "week_sales_cb = transactions_citybags_agg.reset_index(drop=False)\n",
    "week_sales_cb['month_year'] = week_sales_cb['week'].apply(get_month_and_year)\n",
    "\n",
    "# Convert 'month_year' to datetime for sorting in order to keep a chronological order in your plot\n",
    "week_sales_cb['month_year_datetime'] = pd.to_datetime(week_sales_cb['month_year'], format='%b-%Y')\n",
    "\n",
    "## Aggregate to monthly sales:\n",
    "month_sales_cb = week_sales_cb.groupby(by=['month_year_datetime','country'])['sale_amount'].sum().reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a179df5f-bbf9-49a9-8ed7-8706f518afe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_sales_cb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09d6c17-a923-4917-b152-302ae685090f",
   "metadata": {},
   "source": [
    "Now we can create a plot for the two countries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65533f52-696d-49d6-a650-b38eeb9d3dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We split the dataframe for the two regions\n",
    "month_sales_cb_cn = month_sales_cb[month_sales_cb['country'] == 'CHINA'].reset_index(drop=True)\n",
    "month_sales_cb_jp = month_sales_cb[month_sales_cb['country'] == 'JAPAN'].reset_index(drop=True)\n",
    "\n",
    "month_sales_cb_cn = month_sales_cb_cn.rename(columns={'sale_amount': 'China Sales'})\n",
    "month_sales_cb_jp = month_sales_cb_jp.rename(columns={'sale_amount': 'Japan Sales'})\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,10))\n",
    "\n",
    "month_sales_cb_cn.plot(kind='line', figsize=(15,6), y='China Sales', x='month_year_datetime', xlabel='date', ax=ax, title='Sales from 2023 to 2024')\n",
    "month_sales_cb_jp.plot(kind='line', figsize=(15,6), y='Japan Sales', x='month_year_datetime', xlabel='date', ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a461250-2acd-45fb-ae56-8df1e3312498",
   "metadata": {},
   "source": [
    "## Models: Kmeans, Linear Regression and Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728af041-de8d-4659-9dad-9b22cf43ff7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfae73ef-3f98-45c9-a58b-2ef30454b403",
   "metadata": {},
   "source": [
    "### Kmeans to create a products' segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb933d2-3ccc-4a1c-ba13-6e7f904ebb59",
   "metadata": {},
   "source": [
    "Clustering is an unsupervised task used in a wide variety of application, including segmentation and analysis. Let's look here how to create a new segmentation for products based on price and popularity: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e93094d-4339-4f05-a55e-b8f82f452d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_with_product.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594ff4ab-d4a8-4ddd-bbbb-519b9ee593c6",
   "metadata": {},
   "source": [
    "We will use the kmeans clustering algorithm. You can find documentation on the model here: https://scikit-learn.org/1.5/modules/generated/sklearn.cluster.KMeans.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970db27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select the column you want to classify the products on, as well as the product unique identifier that we will want to cluster\n",
    "transactions_with_product_forkmeans = transactions_with_product[['product_id','count_distinct_transaction','price_fr_eur']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748219b8-5317-46b3-8cc9-32370455907f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_with_product_forkmeans.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194bef64-46dc-4526-b159-4bf6f1185436",
   "metadata": {},
   "source": [
    "Since the values of \"price_fr_eur\" is so much higher than \"count_distinct_transaction\", we rework our values so that they are on the same scale. Otherwise, price will overwhelm the number of transaction in terms of importance in the clustering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a6e62a-865a-4409-b905-6624803bed05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the columns for clustering\n",
    "X = transactions_with_product_forkmeans[['count_distinct_transaction', 'price_fr_eur']]\n",
    "\n",
    "# We scale the features using StandardScaler()\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce65041e-0e73-49f2-9f36-c6726f9e9caa",
   "metadata": {},
   "source": [
    "Kmeans need to be told in how many cluster it will gather the data. Therefore we need to identify the right number of clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4cdf21-551b-4e01-83db-02263bcf861c",
   "metadata": {},
   "source": [
    "#### Find the right number of clusters: the elbow method:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b7adaf-564e-4254-b9e0-da2e04f9b089",
   "metadata": {},
   "source": [
    "The elbow method uses the Within Cluster Sum of squares to find the optimal number of clusters. Link:https://www.geeksforgeeks.org/elbow-method-for-optimal-value-of-k-in-kmeans/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7524bb44-8fab-4da0-bb8d-ce8a641a4943",
   "metadata": {},
   "source": [
    "Let us make the plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba46881-95fe-47a4-a668-9705e643c04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the Within-Cluster-Sum-of-Squares (WCSS) for different numbers of clusters\n",
    "wcss = []\n",
    "for k in range(1, 11):  # Testing k values from 1 to 10\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(X_scaled)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "# Plotting the elbow curve\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, 11), wcss, marker='o', linestyle='--')\n",
    "plt.title('Elbow Method for Optimal k')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('WCSS')\n",
    "plt.xticks(range(1, 11))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ff8596-1f83-408b-8558-8c7a6d2aba90",
   "metadata": {},
   "source": [
    "As you can see, the inertia drops very quickly as we increase the number of clusters up to 5 then decreases much more slowly as we keep increasing k. The elbow point typically represents a good balance between minimizing WCSS and not overcomplicating the model. So if we did not know better, 5 might be a good choice as a number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2fe126-5684-4dc5-a1c6-87d956caff2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Applying KMeans with 5 clusters\n",
    "kmeans = KMeans(n_clusters=5, random_state=1234)\n",
    "transactions_with_product_forkmeans['cluster'] = kmeans.fit_predict(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7e3984-bba8-40cc-8c5d-15efa5fdca73",
   "metadata": {},
   "source": [
    "Now we have obtained a cluster for each product id. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63699184-626d-453c-a50a-76cdc403d597",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_with_product_forkmeans.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1232f4-1688-44f9-ad72-0fbca3afeecd",
   "metadata": {},
   "source": [
    "Now let's look at a our clusters from a statistical point of view:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6722e3b5-c0d9-4de2-a605-5d40412cb1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping by cluster and calculating metrics for each field used in clustering\n",
    "result_cluster = transactions_with_product_forkmeans.groupby('cluster').agg(\n",
    "    distinct_product_id=('product_id', 'nunique'), ## Number of product in the cluster\n",
    "    mean_count_distinct_transaction=('count_distinct_transaction', 'mean'), # Average number of transaction per product in the cluster\n",
    "    mean_price_fr_eur=('price_fr_eur', 'mean') # Average price per product in the cluster\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc82564-62b8-4aa1-9897-264e0adf30ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af18c05b-775e-490c-b2f6-af32fa2a5404",
   "metadata": {},
   "source": [
    "Let's analyse the results:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf7e3f4-09b7-46c2-b62b-039a615a1cb8",
   "metadata": {},
   "source": [
    "As you can see, we have 10 products with a very high number of transactions (compared to other clusters) in cluster 3, therefore a cluster made of very popular products. Cluster nbr 3 could be qualified as a \"bestsellers\" cluster. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448e3473-040e-474a-b276-ed0b2dc29d1c",
   "metadata": {},
   "source": [
    "Then, we have a cluster with, on average, more expensive products even though they are less often sold: cluster 2. Therefore, cluster 2 could be \"high-end\" products cluster, with expensive and more exclusive products."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460dfd23-176d-41d2-ba8c-a71745282011",
   "metadata": {},
   "source": [
    "What could be the name of the other clusters and how could you use them?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81ff985-edfd-4d7c-960c-bbc0e0922259",
   "metadata": {},
   "source": [
    "### Linear Regression to predict future sales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1af5ee6-674a-4b6d-82da-2ef065ede242",
   "metadata": {},
   "source": [
    "A linear model makes a prediction by simply computing a weighted sum of the input features plus a constant called the bias term. Here are more information on linear regression: https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LinearRegression.html.\n",
    "We could use it to try and predict future sales amount:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba13681-7ca2-4e08-a3f7-01bbdbf1b3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8705e8-dd70-4eaa-98ab-81db582cad1b",
   "metadata": {},
   "source": [
    "First we will need to convert the year_month column into numerical values (e.g., ordinal values or integers representing time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f03e239-9026-4dec-95d2-7a5fb8d62af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_sales[\"time_index\"] = np.arange(len(month_sales))  # Add time index for linear regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b494f5-3af7-4945-9323-ea5c8680ecc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "X = month_sales[[\"time_index\"]]  # Independent variable (time)\n",
    "y = month_sales[\"sale_amount\"]  # Dependent variable (sales)\n",
    "\n",
    "# Train the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predict for all historical data points\n",
    "month_sales[\"Predicted\"] = model.predict(X)\n",
    "\n",
    "# Predict for future data points. Here we can choose the number of months we want to predict:\n",
    "future_periods = 6  #Number of months to predict\n",
    "last_time_index = month_sales[\"time_index\"].iloc[-1]\n",
    "future_time_index = np.arange(last_time_index + 1, last_time_index + 1 + future_periods).reshape(-1, 1)\n",
    "future_forecast = model.predict(future_time_index)\n",
    "\n",
    "# Create a DataFrame for the forecast\n",
    "forecast_index = pd.date_range(month_sales[\"month_year_datetime\"].iloc[-1] + pd.offsets.MonthBegin(), periods=future_periods, freq=\"ME\")\n",
    "forecast_month_sales = pd.DataFrame({\"Predicted\": future_forecast}, index=forecast_index)\n",
    "\n",
    "# Plot the results\n",
    "plt.plot(month_sales[\"month_year_datetime\"], month_sales[\"sale_amount\"], label=\"Actual\")\n",
    "plt.plot(month_sales[\"month_year_datetime\"], month_sales[\"Predicted\"], label=\"Prediction (Historical)\", linestyle=\"--\", color=\"orange\")\n",
    "plt.plot(forecast_month_sales.index, forecast_month_sales[\"Predicted\"], label=\"Prediction (Future)\", linestyle=\"--\", color=\"red\")\n",
    "plt.xlabel(\"Year-Month\")\n",
    "plt.ylabel(\"Sales Amount\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b70b81-4a56-46e2-8ffa-87ae8fa2bdb8",
   "metadata": {},
   "source": [
    "Here we have a prediction for the next six months but we can see that the prediction for the historical data does not fit the actual sales very well...  How could you improve it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99735b2-bf43-433e-b235-793cdc61aac2",
   "metadata": {},
   "source": [
    "### Decision Tree to find clients' preference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be7da7e-172c-43cb-9ba4-78dc6ba8491c",
   "metadata": {},
   "source": [
    "Our analysis thus far seems to indicate that CITY BAGS are very popular products, purchased by a wide amount of clients. But what about a family of products that is less popular, like TRAVEL? Could we identify which clients would be more amenable to buying travel products? And what their characteristics are?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea543891-b911-437d-b9c4-187dda12afdf",
   "metadata": {},
   "source": [
    "Let's see if we can see which kind of clients' prefer TRAVEL by using a Decision Tree classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb60de56-5dbc-4278-9dd6-9f860bdd4772",
   "metadata": {},
   "source": [
    "Decision Trees are versatile Machine Learning algorithms that can perform both classification and regression tasks, and are capable of fitting complex datasets. Here you can find the documentation: https://scikit-learn.org/1.5/modules/tree.html "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7661d5eb-3bc7-47e7-bb3c-8ba418729278",
   "metadata": {},
   "source": [
    "One of the many qualities of Decision Trees is that they require very little data preparation. In fact they don't require feature scaling or centering at all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee3393a-b62b-4e53-818a-ce2d16368084",
   "metadata": {},
   "source": [
    "In our use case, we are going to use purchases in other categories to try and find a behavioral patterns (that can be used by our business teams) that might predict clients that would enjoy TRAVEL products. Therefore, for this example, all of our data will be numerical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92fa889-2f7d-4afa-bc33-29ac63b87e18",
   "metadata": {},
   "source": [
    "#### Create dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8191edaa-c4cb-4772-9922-c073d5140df8",
   "metadata": {},
   "source": [
    "First we will create a dataframe with each column representing a category of purchase by using the pivot_table method. Link to doc: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.pivot_table.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a123d63-1811-482c-a7ba-965acb2fa9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prepare the data: keep the columns on which you  would like the classification to happen, as well as the target:\n",
    "\n",
    "client_df_for_pred =pd.pivot_table(combined_client, values='items_bought', index=['nationality', 'gender','is_reachable','is_big_client','store_zone'],\n",
    "                       columns=['macro_family'], aggfunc=\"sum\", fill_value=0) ## The fill_value will input 0 if there have been no sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625ca408-3f11-42d9-bc2c-097079c90f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_df_for_pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5432e41f-3d8f-4423-9ef5-c6ca1f9835b1",
   "metadata": {},
   "source": [
    "##### Build Decision Tree:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef7081a-61f6-4370-9cd3-6ddd4d9c1bc5",
   "metadata": {},
   "source": [
    "First we need to build our target. This will be a binary exercise: has a client purchased a travel product or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f999cadd-73ac-4f85-bc85-862e17e75890",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## First step: build your target and your features\n",
    "# Create target (y)\n",
    "y = (client_df_for_pred['TRAVEL'] > 0).astype(int)  # Binary target: 1 if purchased, 0 otherwise\n",
    "\n",
    "## Identify the columns that will be used as features (all product categories, excluding the index and 'TRAVEL' column)\n",
    "X = client_df_for_pred.drop(columns=['TRAVEL'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c4cf49-cc9e-4cec-b8aa-c4dd72144a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train the Decision Tree Classifier\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc933676-1881-4f6b-bf70-16d63ca558ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61977768-62e2-4158-a991-acfa443ff7a9",
   "metadata": {},
   "source": [
    "The accuracy of 0.82 seems pretty good at first glance but let us look a little deeper with the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edae4c0-cd28-414b-96fb-4dd796bead07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Display the confusion matrix\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"No Purchase\", \"Purchase\"], yticklabels=[\"No Purchase\", \"Purchase\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80786cd6-5375-4955-ac31-938845814c15",
   "metadata": {},
   "source": [
    "The results are pretty encouraging ! The Decision Tree seems to be especially good at identifying which clients will not purchase TRAVEL products, with only 12 clients that were predicted as purchasing when they in fact, did not purchase TRAVEL.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700c937a-0138-4fbe-a74f-14fc6b85e100",
   "metadata": {},
   "source": [
    "Let us take a look at the decision tree!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2adece-e32c-4976-9957-832a73bc587e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import necessary packages\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# Plot the Decision Tree\n",
    "plt.figure(figsize=(40, 50))  # Adjust figure size for better readability\n",
    "plot_tree(\n",
    "    clf, \n",
    "    feature_names=X.columns,  # Use feature names for clarity\n",
    "    class_names=[\"No Purchase\", \"Purchase\"],  # Label classes\n",
    "    filled=True,  # Color nodes based on class\n",
    "    rounded=True,  # Round node corners for aesthetics\n",
    "    fontsize=12  # Adjust font size\n",
    ")\n",
    "plt.title(\"Decision Tree Visualization\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa530aa-dce5-478b-80c2-998dfd9e287e",
   "metadata": {},
   "source": [
    "This Decision Tree gives good results but seems overly complicated with often samples of the population that are below 5 before classifying the sample. It seems very hard to identify generalized rules that we could use in a business setting to identify TRAVEL clients.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45db5eb2-eba8-465b-a064-78747a05da05",
   "metadata": {},
   "source": [
    "Decsion Trees make very few assumptions about the training data, they are nonparametric models so the model structure is free to stick closely to the data without constraints, which can lead to overcomplicating and overfitting. To avoid that we need to restrict the Decision Tree's freedom during training.\n",
    "\n",
    "There are several aspects that you can tweak in order to improve the tree and make it usable in a business setting.\n",
    "- The depth of the tree\n",
    "- Should you use gini impurity or entropy?\n",
    "- Tune the hyperparameters: min_samples_split, max_leaf_nodes..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58ba4b9-c008-4d27-982f-e2c6e760bf6a",
   "metadata": {},
   "source": [
    "Can you improve the identification of TRAVEL clients so that it can be used by the business team?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cba3277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Fonction pour convertir 'week' au format correct\n",
    "def convert_week_format(week_str):\n",
    "    if pd.isna(week_str):\n",
    "        return pd.NaT  # Gestion des NaN\n",
    "    match = re.search(r'W?(\\d{4})(\\d{2})', week_str)  # Capture YYYY et WW\n",
    "    if match:\n",
    "        year, week = match.groups()\n",
    "        return pd.to_datetime(f'{year}-{week}-1', format='%Y-%W-%w')  # Convertir en lundi de la semaine\n",
    "    return pd.NaT  # Si erreur, on met NaT\n",
    "\n",
    "# Fusionner transactions et produits\n",
    "transactions_with_product = combined_transactions.merge(combined_products, how='left', on='product_id')\n",
    "\n",
    "# Convertir la colonne 'week' en format datetime\n",
    "transactions_with_product['week'] = transactions_with_product['week'].apply(convert_week_format)\n",
    "\n",
    "# Agréger les ventes par semaine et produit\n",
    "df_sales = transactions_with_product.groupby(['week', 'product_id']).agg({\n",
    "    'product_quantity': 'sum',\n",
    "    'price_fr_eur': 'mean',  # Moyenne du prix\n",
    "    'macro_family': 'first',  # Prendre une seule valeur\n",
    "    'store_type_label': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "# Remplacement des NaN\n",
    "df_sales.fillna({'price_fr_eur': df_sales['price_fr_eur'].median(), 'macro_family': 'Unknown'}, inplace=True)\n",
    "\n",
    "print(df_sales.head())  # Vérification des données\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b347020b",
   "metadata": {},
   "source": [
    "EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307162cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#  Distribution des ventes\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(df_sales['product_quantity'], bins=50, kde=True)\n",
    "plt.title(\"Distribution des quantités vendues\")\n",
    "plt.xlabel(\"Quantité vendue\")\n",
    "plt.ylabel(\"Fréquence\")\n",
    "plt.show()\n",
    "\n",
    "#  Analyse des tendances temporelles\n",
    "df_time_series = df_sales.groupby('week')['product_quantity'].sum()\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(df_time_series, marker='o', linestyle='-')\n",
    "plt.title(\"Tendance des ventes au fil du temps\")\n",
    "plt.xlabel(\"Temps (semaine)\")\n",
    "plt.ylabel(\"Total des ventes\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "#  Décomposition de la série temporelle (trend, saisonnalité, résidu)\n",
    "decomp = sm.tsa.seasonal_decompose(df_time_series, model='additive', period=52)  # 52 semaines = 1 an\n",
    "decomp.plot()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.scatterplot(x=df_sales['price_fr_eur'], y=df_sales['product_quantity'])\n",
    "plt.title(\"Impact du prix sur les ventes\")\n",
    "plt.xlabel(\"Prix (€)\")\n",
    "plt.ylabel(\"Quantité vendue\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae344924",
   "metadata": {},
   "source": [
    "Modélisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea633c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "#  Entraînement du modèle ARIMA\n",
    "train_size = int(len(df_time_series) * 0.8)\n",
    "train, test = df_time_series[:train_size], df_time_series[train_size:]\n",
    "\n",
    "model = ARIMA(train, order=(5,1,0))  # AR(5), I(1), MA(0)\n",
    "model_fit = model.fit()\n",
    "\n",
    "#  Prédictions\n",
    "predictions = model_fit.forecast(steps=len(test))\n",
    "\n",
    "#  Évaluation des erreurs\n",
    "mape = mean_absolute_percentage_error(test, predictions)\n",
    "print(f\"MAPE du modèle ARIMA : {mape:.2%}\")\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(train, label=\"Train\")\n",
    "plt.plot(test, label=\"Test\", color='orange')\n",
    "plt.plot(test.index, predictions, label=\"Prédictions\", color='red', linestyle=\"dashed\")\n",
    "plt.legend()\n",
    "plt.title(\"Prédictions ARIMA vs Réel\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a935d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "#  Correction des erreurs de datetime\n",
    "df_sales['week_num'] = df_sales['week'].dt.isocalendar().week  # Remplace .dt.week\n",
    "df_sales['year'] = df_sales['week'].dt.year\n",
    "\n",
    "#  Définition des features et target\n",
    "features = ['week_num', 'year', 'price_fr_eur']  \n",
    "target = 'product_quantity'\n",
    "\n",
    "X = df_sales[features]\n",
    "y = df_sales[target]\n",
    "\n",
    "#  Séparation Train / Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#  Entraînement du modèle XGBoost\n",
    "xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "#  Prédictions\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "#  Évaluation\n",
    "mape_xgb = mean_absolute_percentage_error(y_test, y_pred)\n",
    "print(f\"MAPE du modèle XGBoost : {mape_xgb:.2%}\")\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r')  # Ligne parfaite\n",
    "plt.xlabel(\"Ventes réelles\")\n",
    "plt.ylabel(\"Prédictions\")\n",
    "plt.title(\"Performance du modèle XGBoost\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0bda09",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bacfcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MAPE ARIMA : {mape:.2%}\")\n",
    "print(f\"MAPE XGBoost : {mape_xgb:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606ef963",
   "metadata": {},
   "source": [
    "Plot pour les Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ff2c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Vérification des données\n",
    "print(combined_client.info())\n",
    "print(combined_client.describe())\n",
    "\n",
    "#  Distribution des clients par nationalité\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.countplot(y=combined_client['nationality'], order=combined_client['nationality'].value_counts().index)\n",
    "plt.title(\"Répartition des clients par nationalité\")\n",
    "plt.show()\n",
    "\n",
    "#  Répartition des clients par genre\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x=combined_client['gender'])\n",
    "plt.title(\"Répartition des clients par genre\")\n",
    "plt.show()\n",
    "\n",
    "#  Répartition des clients par tranche d'âge\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(x=combined_client['age'], order=sorted(combined_client['age'].unique()))\n",
    "plt.title(\"Distribution des clients par tranche d'âge\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b52eb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#  Sélection des features utiles\n",
    "features = ['clients', 'items_bought', 'is_reachable', 'is_big_client']\n",
    "\n",
    "#  Normalisation des données\n",
    "scaler = StandardScaler()\n",
    "client_scaled = scaler.fit_transform(combined_client[features])\n",
    "\n",
    "#  Conversion en DataFrame\n",
    "client_scaled_df = pd.DataFrame(client_scaled, columns=features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27916c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "#  Test de plusieurs nombres de clusters\n",
    "inertia = []\n",
    "K_range = range(2, 11)\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(client_scaled)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "#  Tracé de la méthode du coude\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(K_range, inertia, marker='o')\n",
    "plt.title(\"Méthode du coude : choix du nombre de clusters\")\n",
    "plt.xlabel(\"Nombre de clusters K\")\n",
    "plt.ylabel(\"Inertie\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa8307b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Choix du nombre optimal de clusters (ex : K=4)\n",
    "optimal_k = 4  \n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
    "combined_client['cluster'] = kmeans.fit_predict(client_scaled)\n",
    "\n",
    "#  Visualisation des clusters\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=combined_client['clients'], y=combined_client['items_bought'], hue=combined_client['cluster'], palette=\"viridis\")\n",
    "plt.title(\"Segmentation des clients\")\n",
    "plt.xlabel(\"Nombre de clients\")\n",
    "plt.ylabel(\"Nombre d'articles achetés\")\n",
    "plt.legend(title=\"Cluster\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fce88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Moyenne des variables par cluster\n",
    "cluster_summary = combined_client.groupby(\"cluster\")[features].mean()\n",
    "print(cluster_summary)\n",
    "\n",
    "#  Répartition des clients par segment\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(x=combined_client['cluster'])\n",
    "plt.title(\"Répartition des clients par cluster\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf77a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_products = combined_transactions.groupby('product_id')['product_quantity'].sum().sort_values(ascending=False).head(10)\n",
    "print(top_products)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfd5fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d7fd00",
   "metadata": {},
   "source": [
    "Analyse comparative des ventes Web vs Store Physique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1975115d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_by_store = combined_transactions.groupby(['week', 'store_type_label'])['product_quantity'].sum().reset_index()\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.lineplot(data=sales_by_store, x='week', y='product_quantity', hue='store_type_label')\n",
    "plt.title('Évolution des ventes Web vs Magasins Physiques')\n",
    "plt.xlabel('Semaine')\n",
    "plt.ylabel('Quantité de produits vendus')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53da852",
   "metadata": {},
   "source": [
    "Segmentation clients (KMeans) avec variables clés\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed43125",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_features = combined_client[['clients', 'items_bought', 'is_big_client', 'is_reachable']]\n",
    "kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "combined_client['cluster'] = kmeans.fit_predict(client_features)\n",
    "sns.countplot(x='cluster', hue='store_type_label', data=combined_client)\n",
    "plt.title('Segmentation clients selon le type de magasin')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0a0110",
   "metadata": {},
   "source": [
    "Analyse de l’appétence produit (Produits les plus vendus Web vs Physique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d806108c",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_sales = combined_transactions.groupby(['product_id', 'store_type_label'])['product_quantity'].sum().reset_index()\n",
    "merged_sales = product_sales.merge(combined_products, on='product_id', how='left')\n",
    "top_web_products = merged_sales[merged_sales['store_type_label'] == 'Web'].sort_values(by='product_quantity', ascending=False).head(10)\n",
    "top_store_products = merged_sales[merged_sales['store_type_label'] == 'Physical'].sort_values(by='product_quantity', ascending=False).head(10)\n",
    "print(\"Top 10 produits Web:\")\n",
    "print(top_web_products[['product_id', 'sku_description', 'product_quantity']])\n",
    "print(\"\\nTop 10 produits Magasin:\")\n",
    "print(top_store_products[['product_id', 'sku_description', 'product_quantity']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3431225",
   "metadata": {},
   "source": [
    "Analyse omnicanal (Cross-shop clients entre Web & Store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d7e0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_cross_shop = combined_client.groupby(['store_type_label', 'is_big_client'])['clients'].sum().reset_index()\n",
    "sns.barplot(data=client_cross_shop, x='store_type_label', y='clients', hue='is_big_client')\n",
    "plt.title('Analyse des clients multi-canaux')\n",
    "plt.ylabel('Nombre de clients')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
